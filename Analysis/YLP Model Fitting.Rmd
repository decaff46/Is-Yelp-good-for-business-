---
title: "Is Yelp Helpful to a Restaurant's Sustainability?"
author: "Team XKL"
output:
  pdf_document:
    fig_caption: true
    toc_depth: 2
    number_sections: yes
    includes:
      in_header: preamble-latex.tex
---
\setlength{\topmargin}{3in}

\newpage
\setlength{\topmargin}{-0.5in}
\singlespacing
\tableofcontents
\doublespacing

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(flexdashboard)
library(shiny)
library(rmarkdown)
library(knitr)
library(Hmisc)
library(DT)
library(data.table)
library(RColorBrewer)
library(scales)
library(lattice)
library(tidyverse)
# library(dplyr)
library(magrittr)
library(plotly)
library(leaflet,quietly=TRUE)
library(maps,quietly=TRUE)

library(ggplot2)
library(ROCR)
library(tree)
library(randomForest)
library(maptree)
library(class)
library(gbm)
library(e1071)
library(imager)
library(reshape2)
library(rpart)
library(caret)
library(purrr)
library(adabag)

knitr::opts_chunk$set(echo = FALSE, cache = TRUE, fig.pos = "H")
indent1 = '    '
```

```{r functions}
fill_in_NA <- function(cuisine_ls){
  for(i in cuisine_ls){
    DT[, "idx" := str_detect(DT$categories, i)]
    DT[get("idx") == 1, eval(cuisine.name) := cuisine_ls[1]]
    # DT[get("idx") == 1 & is.na(get(cuisine.name))==TRUE, eval(cuisine.name) := cuisine_ls[1]]
    DT[,"idx":=NULL]
  }
}

erate <- function(predicted.value, true.value){
  return(mean(true.value!=predicted.value))
}

#Set formula
create.formula <- function(outcome.name, input.names, input.patterns = NA, 
                           all.data.names = NA, return.as = "character") {
  variable.names.from.patterns <- c()
  if (!is.na(input.patterns[1]) & !is.na(all.data.names[1])) {
    pattern <- paste(input.patterns, collapse = "|")
    variable.names.from.patterns <- all.data.names[grep(pattern = pattern, x = all.data.names)]
  }
  all.input.names <- unique(c(input.names, variable.names.from.patterns))
  all.input.names <- all.input.names[all.input.names != outcome.name]
  if (!is.na(all.data.names[1])) {
    all.input.names <- all.input.names[all.input.names %in%
    all.data.names]
  }
  input.names.delineated <- sprintf("`%s`", all.input.names)
  the.formula <- sprintf("`%s` ~ %s", outcome.name, paste(input.names.delineated, collapse = " + "))
  if (return.as == "formula") {
    return(as.formula(the.formula))
  }
  if (return.as != "formula") {
    return(the.formula)
  }
}

reduce.formula <- function(dat,the.initial.formula, max.categories= NA){
  require(data.table)
  dat <- setDT(dat)
  
  the.sides <- strsplit(x= the.initial.formula, split="~")[[1]]
  lhs <- trimws(x=the.sides[1], which="both")
  lhs.original <- gsub(pattern = "'",replacement="",x=lhs)
  if (!(lhs.original %in% names(dat))){
    return("Error: Outcome variable is not in names(dat).")
  }
  the.pieces.untrimmed <- strsplit(x= the.sides[2], split= "+", fixed =T)[[1]]
  the.pieces.untrimmed.2 <- gsub(pattern = "'",replacement = "",x= the.pieces.untrimmed, fixed = T)
  the.piece.in.names <- trimws(x= the.pieces.untrimmed.2,which = "both")
  
  the.pieces <- the.piece.in.names[the.piece.in.names %in% names(dat)]
  num.variables <- length(the.pieces)
  include.pieces <- logical(num.variables)
  
  for (i in 1:num.variables){
    unique.values <- dat[,unique(get(the.pieces[i]))]
    num.unique.values <- length(unique.values)
    if (num.unique.values >= 2){
      include.pieces[i] <- TRUE
    }
    if (!is.na(max.categories)){
      if (dat[, is.character(get(the.pieces[i]))|is.factor(get(the.pieces[i]))]==TRUE) {
        if (num.unique.values > max.categories){
          include.pieces[i] <- FALSE
        }
      }
    }
  }
  pieces.rhs <- sprintf("'%s'", the.pieces[include.pieces == TRUE])
  rhs <- paste(pieces.rhs,collapse = "+")
  the.formula <- sprintf("%s ~%s",lhs,rhs)
  return(the.formula)
}

eval.dat <- function(x){
  return(eval(as.name(x)))
}

### Business
fill_in_NA <- function(cuisine_ls){
  cat = cuisine_ls[1]
  # print(cat)
  for(i in cuisine_ls){
    DT[, "idx" := str_detect(DT$categories, i)]
    # DT[get("idx") == 1, eval(cuisine.name) := cuisine_ls[1]]
    DT[get("idx") == 1 & is.na(get(cuisine.name))==TRUE, eval(cuisine.name) := cat]
    DT[,"idx":=NULL]
  }
}

combine_regions <- function(region_ls){
  cat = region_ls[1]
  for(i in region_ls){
    DT[, "idx" := str_detect(DT$cuisine.info, i)]
    DT[get("idx") == 1, eval(cuisine.name) := cat]
    DT[,"idx":=NULL]
  }
}

fill_results <- function(result, model_name){
  record[model_name, ] <<- result[[1]]
  auc[, model_name] <<- result[[2]]
}
```

```{r constants p1}
cities.name <- c("All", "Phoenix", "Las Vegas")
business.id.name = "business_id"
business.name.name = "name"
address.name= "address"
city.name = "city"
state.name = "state"
zipcode.name = "postal_code"
latitude.name = "latitude"
longitude.name = "longitude"
stars.name = "stars"
review.coutn.name = "review_count"
category.name = "categories"
is.open.name = "is_open"
cuisine.name = "cuisine.info"
pattern.attributes <- "Attributes_"

cuisine_american <- c('American', 'American (New)', 'Breakfast & Brunch', 'Burgers', 'Fast Food','American (Traditional)', 'Breakfast & Brunch', 'Burgers', 'Barbeque', 'Cheesesteaks', "Cajun/Creole", 'Steakhouses', 'Sandwiches', 'Pizza', 'Hot Dogs',"Chicken Wings", "Hawaiian", "Delis", "Soul Food", "Diners", "Bagels")
cuisine_bars <- c("Bars","Beer Bar","Breweries","Dive Bars","Cocktail Bars","Music Venues","Nightlife","Sports Bars","Wine Bars","Pubs","Gastropubs","Lounges","Karaoke","Dance Clubs")
cuisine_cafe <- c("Cafes","Bubble Tea","Bakeries","Breakfast & Brunch","Bagels","Juice Bars & Smoothies","Coffee & Tea","Ice Cream & Frozen Yogurt")
cuisine_asian <-c("Asian","Asian Fusion")
cuisine_Vietnamese <- c("Vietnamese", "Pho")
cuisine_vege <-c("Vege", "Gluten-Free","Vegetarian","Vegan")

cuisine_south_asia <- c("South_Asia", "Bangladeshi", "Indian","Pakistani", "Sri Lankan")
# cuisine_east_asia <- c("East_Asia", "Chinese", "Japanese","Korean")
cuisine_se_asia <- c("South_East_Asia", "Filipino", "Indonesian", "Laotian","Malaysian", "Singaporean", "Vietnamese")
cuisine_europe <- c("European", "French", "Greek","Italian","Portuguese","Polish","Russian","Ukrainian")

cuisine_ls <- c(cuisine_american, cuisine_bars, cuisine_cafe, cuisine_asian, cuisine_Vietnamese, cuisine_vege)
# levels(as.factor(DT$cuisine.info))

N <- 10000
c("Classification Tree", "Random Forest", "Logistic Regression", "Support Vector Machine", "KNN", "Naive Bayes") -> ls.models
```

```{r}
### user and restaurant
# user <- fread(input = "../Data/yelp_user.csv", verbose = FALSE)
# restaurant <- fread(input = "../Data/restaurant.csv")

# read.csv("../Data/yelp_business.csv") -> business
# head(business)
# # business[complete.cases(business), ] -> business.comp
# business %>% select(business_id, Attributes_GoodForKids, Attributes_RestaurantsReservations, 
#                     Attributes_GoodForMeal, Attributes_Caters, Attributes_NoiseLevel, 
#                     Attributes_RestaurantsTableService, Attributes_RestaurantsTakeOut, 
#                     Attributes_RestaurantsPriceRange2, Attributes_OutdoorSeating,
#                     Attributes_BikeParking, Attributes_HasTV,Attributes_WiFi,
#                     Attributes_RestaurantsAttire, Attributes_RestaurantsGoodForGroups, 
#                     Attributes_RestaurantsDelivery, Attributes_BusinessAcceptsCreditCards) -> business_selcted_features
# business_selcted_features[complete.cases(business_selcted_features), ] -> business.comp
```

```{r data processing}
set.seed(621)
##################################################################################
# read in saved data
##################################################################################
DT <- readRDS("../Data/full.restaurant.w.cuisine.rds", refhook = NULL)
# all(str_detect(DT$categories, "American") == grepl("American", DT$categories))

##################################################################################
# Fill in NA
##################################################################################
fill_in_NA(cuisine_american); fill_in_NA(cuisine_bars)
fill_in_NA(cuisine_cafe); fill_in_NA(cuisine_asian)
fill_in_NA(cuisine_Vietnamese); fill_in_NA(cuisine_vege)
combine_regions(cuisine_south_asia); combine_regions(cuisine_se_asia)
combine_regions(cuisine_europe)
DT[get(cuisine.name)=="Taiwanese", eval(cuisine.name) := "Chinese"]
DT[get(cuisine.name)=="Armenian", eval(cuisine.name) := "Others"]
DT[is.na(get(cuisine.name))==TRUE, eval(cuisine.name) := "Others"]

##################################################################################
# Sample N Observations and Create Dummies
##################################################################################
## For every unique value in the string column, create a new 1/0 column

DT %>% select(is_open, stars, review_count, cuisine.info, total.sentiment.score, total.num.post) %>%
  sample_n(., N) %>%
  mutate(is_open = ifelse(is_open==1, "Yes", "No")) %>%
  # mutate_if(is.character, as.factor)
  mutate(is_open = as.factor(is_open)) %>%
  mutate(cuisine.info = ifelse(cuisine.info=="Sri Lankan", "Sri_Lankan", cuisine.info))%>%
  mutate(total_sentiment_score=total.sentiment.score,
         total_num_post=total.num.post, 
         cuisine_info = as.factor(cuisine.info)) %>% 
  select(-c(cuisine.info, total.sentiment.score, total.num.post)) -> dat

DT %>% select(is_open, stars, review_count, cuisine.info, total.sentiment.score, total.num.post) %>%
  sample_n(., N) %>%
  mutate(is_open = ifelse(is_open==1, "Yes", "No")) %>%
  mutate(is_open = as.factor(is_open)) %>%
  mutate(cuisine.info = ifelse(cuisine.info=="Sri Lankan", "Sri_Lankan", cuisine.info))%>%
  mutate(total_sentiment_score=total.sentiment.score) %>%
  mutate(total_num_post=total.num.post) -> dat.dummies

for(level in unique(dat.dummies$cuisine.info)){
  dat.dummies[paste("dummy", level, sep = "_")] <- ifelse(dat.dummies$cuisine.info == level, 1, 0)
}
dat.dummies %>% select(-c(cuisine.info, total.sentiment.score, total.num.post)) -> dat.dummies
```

```{r constants p2}
# business <- DT
# attributes.list <- names(business)[grep(pattern = pattern.attributes, x = names(business))]
# 
# unique.id <- business[, unique(get(business.id.name))]
# unique.name <- business[, unique(get(business.name.name))]
# unique.address <- business[, unique(get(address.name))]
# unique.city <- business[, unique(get(city.name))]
# unique.state <- business[, unique(get(state.name))]
# unique.zipcod <- business[, unique(get(zipcode.name))]
# unique.cuisine <- restaurant[, unique(get(cuisine.name))]
# unique.restaurant <- restaurant[, unique(get(business.id.name))]
# 
# num.business <- length(unique.id)
# num.restaurant <- length(unique.restaurant)
# num.cuisine <- length(unique.cuisine)
# 
# respondent.variables1 <- c(city.name, state.name, cuisine.name, review.coutn.name, stars.name)
# respondent.variables2 <- c(stars.name)
# dependent.variables <- c(is.open.name)
```

```{r data split}
set.seed(621)
# is.factor(dat$is_open)

samp <- sample(1:nrow(dat), 0.8*nrow(dat))
trn <- dat[samp,]; test <- dat[-samp,]
trn.dummies <- dat.dummies[samp,]; test.dummies <- dat.dummies[-samp,]
```

```{r 10 folds}
set.seed(621)
nfold <- 10
folds = seq.int(nrow(trn)) %>%       
    cut(breaks = nfold, labels=FALSE) %>%   
    sample()                                  
```

```{r matrix}
## error matrix
record <- matrix(NA, nrow = length(ls.models), ncol = 2)
colnames(record) <- c("Train Error", "Test Error")
rownames(record) <- ls.models

## auc matrix
auc <- matrix(NA, nrow = 1, ncol = length(ls.models))
colnames(auc) <- ls.models
rownames(auc) <-  c("auc")
```

```{r formula}
names <- names(dat)
formula.fit <- as.formula(create.formula(outcome.name = names[1], 
                                         input.names = names[2:length(names)]))
```

\newpage
# Abstract

\newpage
# Introduction

## Project Goal and Background


## Literature Review 


## Data Description

## Relevant Variables

## Purpose and Result


\newpage

# Methods

## Pre-processing 

## Classification Tree

```{r tree model}
model.tree <- function(trn, tst = test, formula = formula.fit, dependent = is.open.name){
  
  features <- setdiff(names(trn), dependent)
  YTrain <- trn[, dependent]; XTrain <- trn[, features]
  YTest <- tst[, dependent]; XTest <- tst[, features]
  
  control <- trainControl(method = "cv", number = 10)
  tunegrid <- expand.grid(.cp = seq(0.01, 0.5, 0.01))
  garbage <- capture.output(tune.ct <- train(formula, data = trn, method = "rpart", trControl = control, tuneGrid = tunegrid))
  
  rpart.model <- rpart(formula, data=trn, method="class", control = rpart.control(cp = tune.ct$bestTune$cp))
  
  pred.tree.trn <- predict(rpart.model, trn, type="class")
  tree.trn.err <- erate(pred.tree.trn, YTrain)
  pred.tree.val <- predict(rpart.model, tst, type="class")
  tree.val.err <- erate(pred.tree.val, YTest)
  
  prob.tree <- predict(rpart.model, XTest)[,2]
  pred.tree <- prediction(prob.tree, YTest)
  perf.tree <- performance(pred.tree, measure = "tpr", x.measure = "fpr")
  auc.tree <- as.numeric(performance(pred.tree, "auc")@y.values)

  return(list(c(tree.trn.err, tree.val.err), auc.tree, perf.tree))
}
```

```{r tree run}
result.tree <- model.tree(trn = trn)
fill_results(result.tree, "Classification Tree")
```


## Random Forest  

```{r random forest, fig.cap="Random Forest Error", fig.height=2.6, fig.width=3.7}
model.rf <- function(trn, tst = test, numTrees = 200, formula = formula.fit, dependent = is.open.name){
  
  features <- setdiff(names(trn), dependent)
  YTrain <- trn[, dependent]; XTrain <- trn[, features]
  YTest <- tst[, dependent]; XTest <- tst[, features]
  
  mod.rf <- randomForest(formula = formula, 
                         data = trn, 
                         ntree = numTrees, 
                         importance = TRUE
                         )
  
  pred.tf.trn <- predict(mod.rf, trn, type="class")
  rf.trn.err <- erate(pred.tf.trn, YTrain)
  pred.rf.val <- predict(mod.rf, test, type="class")
  rf.val.err <- erate(pred.rf.val,YTest)
  
  prob.rf <- predict(mod.rf, XTest, type="prob")[,2]
  pred.rf <- prediction(prob.rf, YTest)
  perf.rf <- performance(pred.rf, measure = "tpr", x.measure = "fpr")
  auc.rf <-  as.numeric(performance(pred.rf, "auc")@y.values)
  
  return(list(c(rf.trn.err, rf.val.err), auc.rf, perf.rf))
}
```

```{r rf run}
result.rf <- model.rf(trn = trn)
fill_results(result.rf, "Random Forest")
# record; auc
```



## Logistic Regression

```{r logit model}
model.logit <- function(trn, tst=test, formula = formula.fit, dependent = is.open.name){
  
  features <- setdiff(names(trn), dependent)
  YTrain <- trn[, dependent]; XTrain <- trn[, features]
  YTest <- tst[, dependent]; XTest <- tst[, features]
  
  glm.fit <- suppressWarnings(glm(formula, data=trn, family=binomial()))
  prob.training <- predict(glm.fit, type="response")
  
  pred.logit <- prediction(prob.training, YTrain)
  perf.logit <- performance(pred.logit, measure="tpr", x.measure="fpr")
  auc.logit <- as.numeric(performance(pred.logit, "auc")@y.values)
  
  fpr <- performance(pred.logit, "fpr")@y.values[[1]]
  cutoff <- performance(pred.logit, "fpr")@x.values[[1]]
  fnr <- performance(pred.logit,"fnr")@y.values[[1]]
  
  rate <- as.data.frame(cbind(Cutoff=cutoff, FPR=fpr, FNR=fnr))
  rate$distance <- sqrt((rate[,2])^2+(rate[,3])^2)
  index <- which.min(rate$distance)
  best.threshold <- rate$Cutoff[index]
  
  matplot(cutoff, cbind(fpr,fnr), type="l",lwd=2, xlab="Threshold",ylab="Error Rate")
  legend("right", legend=c("FPR","FNR"), col=c(1,2), cex=1)
  abline(v=best.threshold, col=3, lty=3, lwd=3)

  pred.logit.trn <- predict(glm.fit,type="response")
  pred.Ytr <- ifelse(pred.logit.trn > best.threshold, "Yes", "No")
  logit.trn.err <- erate(pred.Ytr,YTrain)
  
  pred.logit.test <- predict(glm.fit, test[,-1], type="response")
  pred.Yvl <- ifelse(pred.logit.test > best.threshold, "Yes", "No")
  logit.test.err <- erate(pred.Yvl, YTest)
  
  return(list(c(logit.trn.err, logit.test.err), auc.logit, perf.logit))
}
```

```{r logit run}
result.logit <- model.logit(trn = trn)
fill_results(result.logit, "Logistic Regression")
# record; auc
```

## Support Vector Machine

```{r svm model}
model.svm <- function(trn, tst= test, formula = formula.fit, dependent = is.open.name){
  
  ## standardize continuous variables 
  trn %>% mutate_at(vars("stars", "review_count", "total_sentiment_score", "total_num_post"), 
                      scale) -> trn
  tst %>% mutate_at(vars("stars", "review_count", "total_sentiment_score", "total_num_post"), 
                      scale) -> tst
  
  features <- setdiff(names(trn), dependent)
  YTrain <- trn[, dependent]; XTrain <- trn[, features]
  YTest <- tst[, dependent]; XTest <- tst[, features]
  
  ## creating new formula 
  formula <- as.formula(create.formula(outcome.name = dependent, 
                                         input.names = features))
  
  tune.out <- tune(svm, formula, data = trn, 
                   scale = FALSE,
                   kernel = "radial",                                   
                   ranges = list(
                     cost=c(0.01, 0.1, 1, 10)
                     # gamma = 2^c(-8,-4,0,4)
                     )
                   )  #train to find the best cost
  
  tune.best <- tune.out$best.model
  svm.trn.err <- erate(predict(tune.best, XTrain), YTrain)
  svm.test.err <- erate(predict(tune.best, XTest), YTest)
  
  plot(tune.out, transform.x = log2, transform.y = log2)
  
  predict.svm <- predict(tune.best, XTest, decision.values=TRUE)
  prob.svm <- attr(predict.svm,"decision.values")
  pred.svm <- prediction(prob.svm, YTest)
  perf.svm <- performance(pred.svm,"tpr","fpr")
  auc.svm <- performance(pred.svm,"auc")@y.values[[1]]
  # plot(tune.out, type = "perspective", theta = 120, phi = 45)
  
  return(list(c(svm.trn.err, svm.test.err), auc.svm, perf.svm))
}
```

```{r svm run}
# result.svm <- model.svm(trn = trn.dummies, tst = test.dummies) # 0.2890 0.2835
# save(result.svm, file = "result_svm.rda")
# ls()
load(file = "result_svm.rda")
fill_results(result.svm, "Support Vector Machine")
# record; auc
```

## KNN

```{r knn model}
model.knn <- function(trn, tst = test, dependent = is.open.name){
  
  features <- setdiff(names(trn), dependent)
  YTrain <- trn[, dependent]; XTrain <- trn[, features]
  YTest <- tst[, dependent]; XTest <- tst[, features]
  
  ## Creating new formula 
  names <- names(trn)
  formula <- as.formula(create.formula(outcome.name = dependent, 
                                         input.names = features))
  
  control <- trainControl(method  = "cv", number  = 5)
  garbage <- capture.output(fit <- train(formula,
                                   method     = "knn",
                                   tuneGrid   = expand.grid(k = 1:10),
                                   trControl  = control,
                                   preProcess = "scale",
                                   metric     = "Accuracy",
                                   data       = trn))
  
  pred.YTrn <- knn(train=XTrain, test=XTrain, cl=YTrain, k=fit$bestTune$k)
  pred.YTest <- knn(train=XTrain, test=XTest, cl=YTrain, k=fit$bestTune$k)
  knn.trn.err <- erate(pred.YTrn, YTrain)
  knn.test.err <- erate(pred.YTest, YTest)
  
  fit.knn <- knn(train=XTrain, test=XTest, cl=YTrain, k=fit$bestTune$k, prob = TRUE)
  prob <- attr(fit.knn, "prob")
  prob.knn <- 2*ifelse(fit.knn == "-1", 1-prob, prob) - 1
  pred.knn <- prediction(prob.knn, YTest)
  perf.knn <- performance(pred.knn, "tpr", "fpr")
  auc.knn <- performance(pred.knn,"auc")@y.values[[1]]
  
  return(list(c(knn.trn.err, knn.test.err), auc.knn, perf.knn))
}
```

```{r knn run}
result.knn <- model.knn(trn = trn.dummies, tst = test.dummies)
fill_results(result.knn, "KNN")
# record; auc
```

## Naive Bayes

```{r nb model}
# features <- setdiff(names(trn.dummies), is.open.name)
#   YTrain <- trn.dummies[, is.open.name]; XTrain <- trn.dummies[, features]
#   YTest <- test.dummies[, is.open.name]; XTest <- test.dummies[, features]
#   
#   formula <- as.formula(create.formula(outcome.name = is.open.name, 
#                                          input.names = features))
#   
# NBclassfier = naiveBayes(formula, data=trn.dummies)
#   
#   trainPred=predict(NBclassfier, newdata = trn.dummies, type = "class")
#   trainTable=table(YTrain, trainPred)
#   testPred=predict(NBclassfier, newdata=test.dummies, type="class")
#   testTable=table(YTest, testPred)
#   trainAcc=(trainTable[1,1]+trainTable[2,2])/sum(trainTable)
#   testAcc=(testTable[1,1]+testTable[2,2])/sum(testTable)
#   # message("Accuracy")
```

```{r nb h2o model}
model.nb.h2o <- function(trn, tst = test, dependent = is.open.name){
  
  trn %>%
  filter(!!as.name(dependent) == "Yes") %>%
  select_if(is.numeric) %>%
  cor() %>%
  corrplot::corrplot()
  
  sink("trash.txt")
  library(h2o)
  h2o.no_progress()
  h2o.init()
  sink()
  
  # do a little preprocessing
  preprocess <- preProcess(trn, method = c("BoxCox", "center", "scale", "pca"))
  train_pp   <- predict(preprocess, trn)
  test_pp    <- predict(preprocess, tst)
  
  # convert to h2o objects
  train_pp.h2o <- train_pp %>%
    mutate_if(is.factor, factor, ordered = FALSE) %>%
    as.h2o()
  test_pp.h2o <- test_pp %>%
    mutate_if(is.factor, factor, ordered = FALSE) %>%
    as.h2o()
  
  # get new feature names --> PCA preprocessing reduced and changed some features
  y <- dependent
  x <- setdiff(names(train_pp.h2o), y)
  
  # create tuning grid
  hyper_params <- list(
    laplace = seq(0, 5, by = 0.5)
    )
  
  # build grid search 
  grid <- h2o.grid(
    algorithm = "naivebayes",
    grid_id = "nb_grid",
    x = x, 
    y = y, 
    training_frame = train_pp.h2o, 
    nfolds = 10,
    hyper_params = hyper_params
    )
  
  # Sort the grid models by mse
  sorted_grid <- h2o.getGrid("nb_grid", sort_by = "accuracy", decreasing = TRUE)
  # sorted_grid
  best_h2o_model <- sorted_grid@model_ids[[1]]
  best_model <- h2o.getModel(best_h2o_model)
  
  # confusion matrix of best model
  # h2o.confusionMatrix(best_model)
  
  auc <- h2o.auc(best_model, xval = TRUE)
  fpr <- h2o.performance(best_model, xval = TRUE) %>% h2o.fpr() %>% .[['fpr']]
  tpr <- h2o.performance(best_model, xval = TRUE) %>% h2o.tpr() %>% .[['tpr']]
  data.frame(fpr = fpr, tpr = tpr) -> perf.nb
  #   ggplot(aes(fpr, tpr) ) +
  #   geom_line() + 
  #   ggtitle( sprintf('AUC: %f', auc) )
  
  # evaluate on test set
  # h2o.performance(best_model, newdata = test_pp.h2o)
  
  # predict new data
  # train model
  h2o.predict(best_model, newdata = train_pp.h2o) ->pred.h2o.nb.trn
  erate(as.vector(pred.h2o.nb.trn$predict), trn[, is.open.name]) -> nb.trn.err
  h2o.predict(best_model, newdata = test_pp.h2o) ->pred.h2o.nb.test
  erate(as.vector(pred.h2o.nb.test$predict), tst[, is.open.name]) -> nb.test.err
  
  # shut down h2o
  # h2o.removeAll()
  h2o.shutdown(prompt = FALSE)
  return(list(c(nb.trn.err, nb.test.err), auc, perf.nb))
}
```

```{r nb run, message=FALSE, warning=FALSE}
# trn test 0.2925 0.2885
# dummies 0.296625 0.280000
result.nb <- model.nb.h2o(trn = trn.dummies, tst = test.dummies)
fill_results(result.nb, "Naive Bayes")
# record; auc
```

\newpage
# Results
## Error Table
```{r kable record}
knitr::kable(record, digits = 3, caption = "Errors")
```

## ROC Curve
In addition to compare performance of different models with test and training errors, we will use ROC curves and area under the curve (AUC) to compare performances of different classifiers in `R`. Based on errors and curves, the "best" model we selected from six methods analyzed in this project is Naive Bayes and we will validate our conclusion using results obtained before.  

```{r auc table}
apply(auc, 1, round, 2) -> auc.rounded
sapply(ls.models, function(model.name){paste0(model.name, " = ",
                                              auc.rounded[model.name, ])}) -> ls.models.auc
knitr::kable(auc, digits = 2, caption = "Area Under the Curve")
```


```{r roc curves, fig.cap="ROC Curves", fig.height=3.6, fig.width=5.3}
# Classification tree
plot(result.tree[[3]], col='pink',lwd = 2, main="ROC Curves")
legend('bottomright', ls.models.auc, 
       lwd=c(1, 1), 
       col=c("pink","plum",'palegreen', 'skyblue', 'orange', 'grey'), cex = 0.6)

# random forest 
plot(result.rf[[3]], col='plum',lwd = 2, add=TRUE)

# logistic regression 
plot(result.logit[[3]], col='palegreen', add=TRUE, lwd = 2)

# svm
plot(result.svm[[3]], col='skyblue', add=TRUE, lwd = 2)

# knn
plot(result.knn[[3]], col='orange', add=TRUE, lwd = 2)

# naive bayes
lines(result.nb[[3]], col = 'grey', lty=1, lwd = 2)
```

\newpage

# Discussion

